{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "from textblob import TextBlob, Word\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from datetime import datetime\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler \n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTEENN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('rewrite_video_game_.csv',\n",
    "                   encoding='utf-8',  \n",
    "                    engine='python',\n",
    "                   memory_map=True,\n",
    "                   error_bad_lines=False,\n",
    "                    na_values='NaN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['pos_neg']=['Positive' if x> 3 else 'Negative' for x in data.star_rating]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data[['review_body','review_headline','star_rating','pos_neg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('rewrite_video_game_.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data['review_body'].values\n",
    "y=data['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['pos_neg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99994,), (99994,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99994, 82300)\n"
     ]
    }
   ],
   "source": [
    "#TfidfVectorizer\n",
    "vect=TfidfVectorizer()\n",
    "X = vect.fit_transform(X)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({5: 57501, 4: 17684, 1: 10703, 3: 8743, 2: 5363})\n",
      "Resampled dataset shape Counter({1: 57501, 2: 57501, 3: 57501, 4: 57501, 5: 57501})\n",
      "0:10:35.437773\n"
     ]
    }
   ],
   "source": [
    "# Perform SMOTE\n",
    "t1 = datetime.now()\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "sm = SMOTE(random_state=100)\n",
    "X_res, y_res = sm.fit_sample(X, y) \n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.57535251, 0.57845262, 0.57648588, 0.57755259, 0.57581919,\n",
       "       0.5760192 , 0.57571919, 0.58055269, 0.57028568, 0.57348578])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1)\n",
    "nbclf=MultinomialNB(alpha=1)\n",
    "\n",
    "cv = ShuffleSplit(n_splits=10, test_size=0.3, random_state=0)\n",
    "cross_val_score(nbclf, X, y, cv=cv)\n",
    "                                                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "   Negative       0.98      0.07      0.13     24809\n",
      "   Positive       0.76      1.00      0.87     75185\n",
      "\n",
      "avg / total       0.82      0.77      0.68     99994\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nbclf=MultinomialNB(alpha=1)\n",
    "svmclf=svm.SVC(C=1.0,kernel='linear')\n",
    "from sklearn.pipeline import Pipeline\n",
    "text_clf=Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),])\n",
    "score = cross_validation.cross_val_predict(text_clf,X,y,cv=10)\n",
    "print(classification_report(y,score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#HashingVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "vect = HashingVectorizer()\n",
    "train_dtm = vect.transform(X)\n",
    "print(train_dtm.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_dtm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "t1 = datetime.now()\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "rus = RandomUnderSampler(random_state=100)\n",
    "X_res, y_res = rus.fit_sample(train_dtm, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from imblearn.under_sampling import ClusterCentroids\n",
    "\n",
    "t1 = datetime.now()\n",
    "cc = ClusterCentroids(random_state=100)\n",
    "X_res, y_res = cc.fit_sample(train_dtm, y)\n",
    "\n",
    "print(datetime.now() - t1)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# under_sampling ALLKNN\n",
    "from imblearn.under_sampling import AllKNN \n",
    "t1 = datetime.now()\n",
    "\n",
    "allknn = AllKNN(random_state=100)\n",
    "X_res, y_res = allknn.fit_sample(train_dtm, y)\n",
    "\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SMOTE\n",
    "t1 = datetime.now()\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "sm = SMOTE(random_state=100)\n",
    "X_res, y_res = sm.fit_sample(train_dtm, y) \n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#SMOTEENN\n",
    "# Not the same sample\n",
    "t1 = datetime.now()\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "smenn = SMOTEENN(random_state=100)\n",
    "X_res, y_res = smenn.fit_sample(train_dtm, y) \n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res , test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "t1 = datetime.now()\n",
    "#LogisticRegression\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression CV\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "t1 = datetime.now()\n",
    "\n",
    "logreg = LogisticRegressionCV(cv=10)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_class = logreg.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LinearSVC\n",
    "from sklearn.svm import LinearSVC\n",
    "t1 = datetime.now()\n",
    "\n",
    "#LinearSVC\n",
    "lin_clf = LinearSVC()\n",
    "clf=lin_clf.fit(X_train, y_train)\n",
    "y_pred_class = clf.predict(X_test)\n",
    "print(classification_report(y_test,y_pred_class))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CountVectorizer\n",
    "vect = CountVectorizer()\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "test_dtm = vect.transform(X_test)\n",
    "\n",
    "train_dtm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res , test_size=0.3, random_state=100)\n",
    "\n",
    "#RandomUnderSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "t1 = datetime.now()\n",
    "print('Original dataset shape {}'.format(Counter(y)))\n",
    "rus = RandomUnderSampler(random_state=100)\n",
    "X_res, y_res = rus.fit_sample(train_dtm, y)\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def balance_classes(xs, ys):\n",
    "    freqs = Counter(ys)\n",
    "\n",
    "# the least common class is the maximum number we want for all classes\n",
    "    max_allowable = freqs.most_common()[-1][1]\n",
    "    num_added = {clss: 0 for clss in freqs.keys()}\n",
    "    new_ys = []\n",
    "    new_xs = []\n",
    "    for i, y in enumerate(ys):\n",
    "        if num_added[y] < max_allowable:\n",
    "            new_ys.append(y)\n",
    "            new_xs.append(xs[i])\n",
    "            num_added[y] += 1\n",
    "    return new_xs, new_ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the new DataFrame into training and testing sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(Counter(y))\n",
    "balanced_x, balanced_y = balance_classes(X, y)\n",
    "print(Counter(balanced_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "balanced_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(balanced_x, balanced_y, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer()\n",
    "train_dtm = vect.fit_transform(X_train)\n",
    "\n",
    "test_dtm = vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dtm"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.svm import SVC\n",
    "lin_clf = SVC()\n",
    "lin_clf.fit(train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(test_dtm)\n",
    "print(classification_report(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "#LinearSVC\n",
    "lin_clf = LinearSVC()\n",
    "lin_clf.fit(train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(test_dtm)\n",
    "print(classification_report(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "In practice, one-vs-rest classification is usually preferred, since the results are mostly similar, but the runtime is significantly less."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LogisticRegression\n",
    "logreg = LogisticRegression(C=1e9)\n",
    "logreg.fit(train_dtm, y_train)\n",
    "y_pred_class = logreg.predict(test_dtm)\n",
    "print (metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test,y_pred_class ))\n",
    "print('\\n')\n",
    "print(classification_report(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use Naive Bayes to predict the star rating\n",
    "nb = MultinomialNB()\n",
    "nb.fit(train_dtm, y_train)\n",
    "y_pred_class = nb.predict(test_dtm)\n",
    "print(classification_report(y_test,y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=data['review_body'].values\n",
    "stars=data['star_rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balance_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This vectorizer breaks text into single words and bi-grams\n",
    "# and then calculates the TF-IDF representation\n",
    "vectorizer = TfidfVectorizer(ngram_range=(1,2))\n",
    "t1 = datetime.now()\n",
    "\n",
    "# the 'fit' builds up the vocabulary from all the reviews\n",
    "# while the 'transform' step turns each indivdual text into\n",
    "# a matrix of numbers.\n",
    "vectors = vectorizer.fit_transform(balanced_x)\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "# initialise the SVM classifier\n",
    "classifier = LinearSVC()\n",
    " \n",
    "# train the classifier\n",
    "t1 = datetime.now()\n",
    "classifier.fit(X_train, y_train)\n",
    "print(datetime.now() - t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = classifier.predict(X_test)\n",
    "print(list(preds[:10]))\n",
    "print(y_test[:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, preds))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
